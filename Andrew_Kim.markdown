Andrew Kim
===============

_2716 Wander LN, Alpharetta GA 30022_  
_404-922-9111 / bryan238@gmail.com_

Objective
---------

To be in the Microsoft Leap Apprenticeship Program, to learn about 
Technical Program Manager and to obtain the full time position at Microsoft.

Summary of Qualifications
-------------------------

* Creation of ingestion and data transformation processes utilizing Spark, Flume, Hive, and
Oozie.
* Knowledgeable of Hadoop file storage types and when compression utilization is
appropriate. Also how to structure the data appropriately based on the tool used for
access.
* Extensive knowledge of traditional Data Warehousing technologies such as ETL,
Relational Data Base Management Systems, SQL, and Data Modeling.
* Automating of workflows using Oozie, Airflow and ETL tools.
* Build End-to-End architecture and pipeline to migrate traditional data warehouse to
Azure platform to modernize BI projects and Data Science projects.
* Managing Internal and External Data Engineering team to migrate ODS and DW data into Cloud.

Technical Profile
-----------------

### Programming Languages:

Python, Scala, MSSQL, Java, Shell

### Big Data:

Spark, Airflow, Kafka, Hive

### Azure:

ADLS, Synapse, Function App, Application Insight, ADX, Azure DevOps, ADF, Databricks

### Operating Systems:

Linux, MAC OS, Windows

Certifications and Education
----------------------------

* Bachelor of Arts in Computer Science, Georgia State University,
  Atlanta, GA (MAY, 2015)

Professional Experience
-----------------------

### Mercedes Benz USA (Atlanta, GA)

_Senior Software Engineer (Data Engineering), APR 2019 - Present_

* Built an architecture to migrate current Enterprise Data Warehouse to Cloud
Platform using ADF and Databricks
* Built a data quality check program to check data using business rules before the
delivery using Function app and app insight. (C#)
* Built ELT program to extract the data from OPS (10GB/Day) to ADLS and ADW
using ADF and Databricks to enable it as daily automation process (Python)
* Data-modeling and Data-architecture using Erwin
* Working with sales ops group to built pipelines to delivered the data and
productionize the prediction model to optimize the bonus program by 20
percent. (Python)
* Working with re-marketing team and finance team to build pipelines from
multiple organization at Daimler AG to build predictive model for used car price
(Python)
* Leading MBUSA Internal and External Data Engineering team using Agile
methodology to migrate on prem data sources (100+) into Cloud platform.

### Travelport (Atlanta, GA)

_SOFTWARE ENGINEER (DATA ENGINEERING), OCT 2014 - APR 2019_

* Installed and performed capability and applicability of big data tools, including
IBM, Cloudera, and open source (Hortonworks Sandbox, Apache Hadoop/Hive,
elasticsearch, and etc.)
* Create(d) a logger to collect metrics from multiple applications for monitoring
and analysis using metric collector (Kafka, Java)
* Built an application to transform real-time data (1TB/hour) and feed to HDFS in
AVRO file format using web application and KAFKA (Java)
* Built a application using ElasticSearch for indexing and searching large set of
PNR/traveler transaction data using its clients
* Using Jenkins to automate the deploy system, and get notified if there is any
error on previous update.

Project
-----------------------

### AZURE AND DYNAMIC COVID ALERTING

_PERSONAL RESEARCH (June 2020 â€“ August 2020)_

* Tech Stack: Event Hub, Function App, Data Explorer, Data Factory, Application
Insight
* Using Function app and Event hub to stream the Bing search data into ADX
database using Bing rest API and created the database structure.
* Created Function and orchestrated the workflow using ADF to collect
telemetry from ADX database into app insight.
* Create a alert from app insight if the alert system notice any abnormal activity
within an hour.
